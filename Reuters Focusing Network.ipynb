{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH']=\"true\"\n",
    "#!pip install numpy==1.16.1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/btek/.conda/envs/kerasgpu/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "SEARCHING /home/btek/.keras/datasets/reuters.npz reuters.npz\n",
      "46 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation,BatchNormalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "max_words = 1000\n",
    "print('Loading data...')\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(path=\"reuters.npz\",\n",
    "                                                         num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=113,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Vectorizing sequence data...')\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is to allow focusing layer more room in the input domain\n",
    "pad = 9\n",
    "x_train_2 = np.zeros(shape=(x_train.shape[0],x_train.shape[1]+2*pad), dtype=x_train.dtype)\n",
    "x_test_2 = np.zeros(shape=(x_test.shape[0],x_test.shape[1]+2*pad), dtype=x_test.dtype)\n",
    "x_train_2[:,pad:-pad]=x_train\n",
    "x_test_2[:,pad:-pad]=x_test\n",
    "max_words2 = max_words+2*pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_utils import SGDwithLR, RMSpropwithClip\n",
    "lr_dict = {'all':5e-5,\n",
    "           'focus-1/Sigma:0': 0.001,'focus-1/Mu:0': 0.001,'focus-1/Weights:0': 0.0001,\n",
    "           'focus-2/Sigma:0': 0.001,'focus-2/Mu:0': 0.001,'focus-2/Weights:0': 0.0001,\n",
    "           'dense_1/Weights:0':5e-5}\n",
    "\n",
    "mom_dict = {'all':0.9}\n",
    "    \n",
    "decay_dict = {'all':0.9, 'focus-1/Sigma:0': 0.1,'focus-1/Mu:0':0.1,\n",
    "              'focus-2/Sigma:0': 0.1,'focus-2/Mu:0': 0.1}\n",
    "batch_size = 16\n",
    "e_i = x_train.shape[0] // batch_size\n",
    "\n",
    "decay_epochs =np.array([e_i*30], dtype='int64')\n",
    "    \n",
    "\n",
    "clip_dict = {'focus-1/Sigma:0':(0.05,1.0),'focus-1/Mu:0':(0.0,1.0),\n",
    "             'focus-2/Sigma:0':(0.05,1.0),'focus-2/Mu:0':(0.0,1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from Kfocusing import FocusedLayer1D\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "\n",
    "\n",
    "\n",
    "def build_model(N=512, mod='dense', optimizer_s='SGDwithLR',inp_shape=None):\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    #model.add(Dropout(0.02))\n",
    "    if mod=='dense':\n",
    "        model.add(Dense(N, activation='relu',name='dense-1',input_shape=inp_shape))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(N, activation='relu',name='dense-2'))\n",
    "    elif mod=='focused':\n",
    "        model.add(FocusedLayer1D(units=N,\n",
    "                                  name='focus-1',\n",
    "                                  activation='linear',\n",
    "                                  init_sigma=0.25, \n",
    "                                  init_mu='spread',\n",
    "                                  init_w= None,\n",
    "                                  train_sigma=True, \n",
    "                                  train_weights=True,\n",
    "                                  train_mu = True,normed=2,input_shape=inp_shape))\n",
    "        \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(FocusedLayer1D(units=N,\n",
    "                                  name='focus-2',\n",
    "                                  activation='linear',\n",
    "                                  init_sigma=0.25, \n",
    "                                  init_mu='spread',\n",
    "                                  init_w= None,\n",
    "                                  train_sigma=True, \n",
    "                                  train_weights=True,\n",
    "                                  train_mu = True,normed=2))\n",
    "        \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(num_classes, name='dense-3'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "\n",
    "    if optimizer_s == 'SGDwithLR':\n",
    "        opt = SGDwithLR(lr_dict, mom_dict,decay_dict,clip_dict, decay_epochs=decay_epochs)\n",
    "    elif optimizer_s=='RMSpropwithClip':\n",
    "        opt = RMSpropwithClip(lr=0.001, rho=0.9, epsilon=None, decay=None,clips=clip_dict)\n",
    "    else:\n",
    "        opt= SGD(lr=0.01, momentum=0.9)#, decay=None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'focus-1', 'input_shape': (1000,)}\n",
      "{'name': 'focus-2'}\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/15\n",
      " - 4s - loss: 2.0822 - acc: 0.4840 - val_loss: 2.6453 - val_acc: 0.3620\n",
      "Epoch 2/15\n",
      " - 3s - loss: 2.4218 - acc: 0.3488 - val_loss: 2.4240 - val_acc: 0.3620\n",
      "Epoch 3/15\n",
      " - 3s - loss: 2.4179 - acc: 0.3511 - val_loss: 2.4158 - val_acc: 0.3620\n",
      "Epoch 4/15\n",
      " - 3s - loss: 2.4145 - acc: 0.3500 - val_loss: 2.4188 - val_acc: 0.3620\n",
      "Epoch 5/15\n",
      " - 3s - loss: 2.4149 - acc: 0.3504 - val_loss: 2.4168 - val_acc: 0.3620\n",
      "Epoch 6/15\n",
      " - 3s - loss: 2.4141 - acc: 0.3516 - val_loss: 2.4228 - val_acc: 0.3620\n",
      "Epoch 7/15\n",
      " - 3s - loss: 2.4110 - acc: 0.3519 - val_loss: 2.4159 - val_acc: 0.3620\n",
      "Epoch 8/15\n",
      " - 3s - loss: 2.4108 - acc: 0.3517 - val_loss: 2.4178 - val_acc: 0.3620\n",
      "Epoch 9/15\n",
      " - 3s - loss: 2.4107 - acc: 0.3516 - val_loss: 2.4201 - val_acc: 0.3620\n",
      "Epoch 10/15\n",
      " - 3s - loss: 2.4118 - acc: 0.3517 - val_loss: 2.4173 - val_acc: 0.3620\n",
      "Epoch 11/15\n",
      " - 3s - loss: 2.4125 - acc: 0.3510 - val_loss: 2.4259 - val_acc: 0.3620\n",
      "Epoch 12/15\n",
      " - 3s - loss: 2.4098 - acc: 0.3517 - val_loss: 2.4200 - val_acc: 0.3620\n",
      "Epoch 13/15\n",
      " - 3s - loss: 2.4108 - acc: 0.3517 - val_loss: 2.4174 - val_acc: 0.3620\n",
      "Epoch 14/15\n",
      " - 3s - loss: 2.4108 - acc: 0.3517 - val_loss: 2.4195 - val_acc: 0.3620\n",
      "Epoch 15/15\n",
      " - 3s - loss: 2.4093 - acc: 0.3517 - val_loss: 2.4155 - val_acc: 0.3620\n",
      "2246/2246 [==============================] - 0s 93us/step\n",
      "Test score: 2.415470719443616\n",
      "Test accuracy: 0.36197684778237277\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 15\n",
    "model1 = build_model(N=150, mod='focused',optimizer_s=SGDwithLR,inp_shape=(max_words,))\n",
    "history_focused = model1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=2,\n",
    "                    validation_data=(x_test,y_test))\n",
    "score = model1.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 15\n",
    "model2 = build_model(N=150, mod='dense',optimizer_s=RMSpropwithClip,inp_shape=(max_words,))\n",
    "history_dense = model2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_split=0.1)\n",
    "score = model2.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
